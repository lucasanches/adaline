{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from itertools import batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando os datasets\n",
    "df_train_loaded = pd.read_csv(\"arquivos_csv/train_dataset1.csv\")\n",
    "df_test_loaded = pd.read_csv(\"arquivos_csv/test_dataset1.csv\")\n",
    "\n",
    "\n",
    "# Separando os dados de treinamento\n",
    "X_train = df_train_loaded.drop(\"label\", axis=1).values      # (n_features, n_amostras)\n",
    "y_train = df_train_loaded[\"label\"].values.reshape(1, -1).T    # (1, n_amostras)\n",
    "\n",
    "# Separando os dados de teste\n",
    "X_test = df_test_loaded.drop(\"label\", axis=1).values\n",
    "y_test = df_test_loaded[\"label\"].values.reshape(1, -1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinamento(X_train, y_train, qtd_atributos, tx_aprendizagem, epocas, batch, precisao=1e-6, seed=None):\n",
    "    \"\"\"\n",
    "        Argumentos:\n",
    "        X_train -- matriz de entrada contendo as amostras de treino\n",
    "        y_train -- vetor contendo os rótulos desejados para as amostras de treino\n",
    "        qtd_atributos -- número de (features) presentes nas amostras\n",
    "        tx_aprendizagem -- taxa de aprendizado, define o passo da atualização dos pesos\n",
    "        epocas -- número máximo de ciclos completos sobre o conjunto de treinamento\n",
    "        batch -- se True, o treinamento ocorre por lotes e se None, o treinamento ocorre por amostra\n",
    "        precisao -- critério de parada baseado na diferença entre EQM de épocas consecutivas\n",
    "        seed -- semente para inicialização dos pesos aleatórios\n",
    "        \n",
    "        Saída:\n",
    "        parâmetros -- python dict contendo:\n",
    "                        pesos -- vetor de pesos ajustados após o treinamento\n",
    "                        epocas_executadas -- número total de épocas percorridas até a convergência\n",
    "                        historico_erro -- lista com a evolução do erro de classificação ao longo das épocas\n",
    "    \"\"\"\n",
    "\n",
    "    if seed is not None:                            # iniciando o vetor de pesos\n",
    "        num_aleatorio = np.random.seed(seed)\n",
    "        pesos = num_aleatorio.random.uniform(low=-1, high=1, size=((qtd_atributos + 1),))   # vetor de peso (atributos + bias)\n",
    "    else:\n",
    "        pesos = np.random.uniform(low=-1, high=1, size=((qtd_atributos + 1),))              # vetor de peso (atributos + bias)\n",
    "\n",
    "    X = np.c_[np.ones(len(X_train)), X_train]\n",
    "    y = y_train.flatten()                           # garantindo que é um vetor unidimensional\n",
    "\n",
    "    evolucao_erro = []\n",
    "    epoca = 0\n",
    "\n",
    "    while epoca < epocas:\n",
    "        erro = 0\n",
    "\n",
    "        if epoca > 0:\n",
    "            EQM_anterior = np.mean((y - np.dot(X, pesos))**2)\n",
    "        else:\n",
    "            EQM_anterior = 1e6              # tratamento para a primeira epoca\n",
    "        \n",
    "        if batch:                           # treinamento por lote (batch)\n",
    "            u = np.dot(X, pesos)            # potencial de ativação\n",
    "            erro = y - u\n",
    "            pesos += tx_aprendizagem * np.dot(X.T, erro)\n",
    "        \n",
    "        else:                               # treinamento por amostra\n",
    "            for amostra in range(len(X)):\n",
    "                u = np.dot(pesos, X[amostra])   # potencial de ativação\n",
    "                erro = y[amostra] - u\n",
    "                pesos += tx_aprendizagem * erro * X[amostra]\n",
    "        \n",
    "        epoca += 1\n",
    "        \n",
    "        EQM_atual = np.mean((y - np.dot(X, pesos))**2)\n",
    "        \n",
    "        predicoes = np.where(np.dot(X, pesos) >= 0, 1, -1)\n",
    "        erro = np.count_nonzero(predicoes - y)\n",
    "        evolucao_erro.append(erro/len(y))\n",
    "        \n",
    "        if np.abs(EQM_atual - EQM_anterior) <= precisao:\n",
    "            break\n",
    "    \n",
    "    return pesos, epoca, evolucao_erro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
